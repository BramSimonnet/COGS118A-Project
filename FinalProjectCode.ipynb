{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adult Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7x/jtprqt351tn3_hbj751vpskc0000gn/T/ipykernel_20118/3606740371.py:20: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  adult['income'] = adult['income'].str.strip().replace({'>50K.': -1, '<=50K.': 1, '>50K': -1, '<=50K': 1})\n",
      "/var/folders/7x/jtprqt351tn3_hbj751vpskc0000gn/T/ipykernel_20118/3606740371.py:62: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  adult[column] = adult[column].replace({True: 1, False: -1})  # Replace True with 1 and False with -1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>race_Asian-Pac-Islander</th>\n",
       "      <th>race_Black</th>\n",
       "      <th>race_Other</th>\n",
       "      <th>race_White</th>\n",
       "      <th>sex_Male</th>\n",
       "      <th>native-country_Central_South_America</th>\n",
       "      <th>native-country_Europe</th>\n",
       "      <th>native-country_North_America</th>\n",
       "      <th>native-country_Other</th>\n",
       "      <th>native-country_Unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>39</td>\n",
       "      <td>215419</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>64</td>\n",
       "      <td>321403</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>38</td>\n",
       "      <td>374983</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>44</td>\n",
       "      <td>83891</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>35</td>\n",
       "      <td>182148</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  fnlwgt  education-num  marital-status  capital-gain  capital-loss  \\\n",
       "0       39   77516             13              -1          2174             0   \n",
       "1       50   83311             13               1             0             0   \n",
       "2       38  215646              9              -1             0             0   \n",
       "3       53  234721              7               1             0             0   \n",
       "4       28  338409             13               1             0             0   \n",
       "...    ...     ...            ...             ...           ...           ...   \n",
       "48837   39  215419             13              -1             0             0   \n",
       "48838   64  321403              9              -1             0             0   \n",
       "48839   38  374983             13               1             0             0   \n",
       "48840   44   83891             13              -1          5455             0   \n",
       "48841   35  182148             13               1             0             0   \n",
       "\n",
       "       hours-per-week  income  workclass_Federal-gov  workclass_Local-gov  \\\n",
       "0                  40       1                     -1                   -1   \n",
       "1                  13       1                     -1                   -1   \n",
       "2                  40       1                     -1                   -1   \n",
       "3                  40       1                     -1                   -1   \n",
       "4                  40       1                     -1                   -1   \n",
       "...               ...     ...                    ...                  ...   \n",
       "48837              36       1                     -1                   -1   \n",
       "48838              40       1                     -1                   -1   \n",
       "48839              50       1                     -1                   -1   \n",
       "48840              40       1                     -1                   -1   \n",
       "48841              60      -1                     -1                   -1   \n",
       "\n",
       "       ...  race_Asian-Pac-Islander  race_Black  race_Other  race_White  \\\n",
       "0      ...                       -1          -1          -1           1   \n",
       "1      ...                       -1          -1          -1           1   \n",
       "2      ...                       -1          -1          -1           1   \n",
       "3      ...                       -1           1          -1          -1   \n",
       "4      ...                       -1           1          -1          -1   \n",
       "...    ...                      ...         ...         ...         ...   \n",
       "48837  ...                       -1          -1          -1           1   \n",
       "48838  ...                       -1           1          -1          -1   \n",
       "48839  ...                       -1          -1          -1           1   \n",
       "48840  ...                        1          -1          -1          -1   \n",
       "48841  ...                       -1          -1          -1           1   \n",
       "\n",
       "       sex_Male  native-country_Central_South_America  native-country_Europe  \\\n",
       "0             1                                    -1                     -1   \n",
       "1             1                                    -1                     -1   \n",
       "2             1                                    -1                     -1   \n",
       "3             1                                    -1                     -1   \n",
       "4            -1                                     1                     -1   \n",
       "...         ...                                   ...                    ...   \n",
       "48837        -1                                    -1                     -1   \n",
       "48838         1                                    -1                     -1   \n",
       "48839         1                                    -1                     -1   \n",
       "48840         1                                    -1                     -1   \n",
       "48841         1                                    -1                     -1   \n",
       "\n",
       "       native-country_North_America  native-country_Other  \\\n",
       "0                                 1                    -1   \n",
       "1                                 1                    -1   \n",
       "2                                 1                    -1   \n",
       "3                                 1                    -1   \n",
       "4                                -1                    -1   \n",
       "...                             ...                   ...   \n",
       "48837                             1                    -1   \n",
       "48838                             1                    -1   \n",
       "48839                             1                    -1   \n",
       "48840                             1                    -1   \n",
       "48841                             1                    -1   \n",
       "\n",
       "       native-country_Unknown  \n",
       "0                          -1  \n",
       "1                          -1  \n",
       "2                          -1  \n",
       "3                          -1  \n",
       "4                          -1  \n",
       "...                       ...  \n",
       "48837                      -1  \n",
       "48838                      -1  \n",
       "48839                      -1  \n",
       "48840                      -1  \n",
       "48841                      -1  \n",
       "\n",
       "[48842 rows x 60 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define column headers\n",
    "columns = [\n",
    "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\",\n",
    "    \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\",\n",
    "    \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"\n",
    "]\n",
    "\n",
    "# Load data and combine training/testing datasets for consistent processing\n",
    "train_data = pd.read_csv(\"adult.data\", header=None, names=columns, na_values=\" ?\", skipinitialspace=True)\n",
    "test_data = pd.read_csv(\"adult.test\", header=None, names=columns, na_values=\" ?\", skipinitialspace=True, skiprows=1)\n",
    "adult = pd.concat([train_data, test_data], ignore_index=True)\n",
    "\n",
    "# Drop rows with missing values\n",
    "adult.dropna(axis=0, inplace=True)\n",
    "\n",
    "# Strip whitespace and map income to binary values (-1 for '>50K', 1 for '<=50K')\n",
    "adult['income'] = adult['income'].str.strip().replace({'>50K.': -1, '<=50K.': 1, '>50K': -1, '<=50K': 1})\n",
    "\n",
    "# Process 'marital-status' into binary categories\n",
    "couple_status = [\"Married-civ-spouse\", \"Married-spouse-absent\", \"Married-AF-spouse\"]\n",
    "single_status = [\"Never-married\", \"Divorced\", \"Separated\", \"Widowed\"]\n",
    "adult['marital-status'] = adult['marital-status'].apply(lambda x: 1 if x in couple_status else -1)\n",
    "\n",
    "# One-hot encode categorical columns (excluding 'native-country')\n",
    "categorical_columns = ['workclass', 'education', 'occupation', 'relationship', 'race', 'sex']\n",
    "adult = pd.get_dummies(adult, columns=categorical_columns, prefix_sep='_', drop_first=True)\n",
    "\n",
    "# Group 'native-country' into regions and one-hot encode\n",
    "def map_country_to_region(country):\n",
    "    region_mapping = {\n",
    "        \"United-States\": \"North_America\", \"Canada\": \"North_America\", \"Mexico\": \"North_America\",\n",
    "        \"Puerto-Rico\": \"North_America\", \"Outlying-US(Guam-USVI-etc)\": \"North_America\",\n",
    "        \"Cuba\": \"Central_South_America\", \"Jamaica\": \"Central_South_America\",\n",
    "        \"Honduras\": \"Central_South_America\", \"Columbia\": \"Central_South_America\",\n",
    "        \"Ecuador\": \"Central_South_America\", \"Dominican-Republic\": \"Central_South_America\",\n",
    "        \"El-Salvador\": \"Central_South_America\", \"Guatemala\": \"Central_South_America\",\n",
    "        \"Trinadad&Tobago\": \"Central_South_America\", \"Nicaragua\": \"Central_South_America\",\n",
    "        \"Peru\": \"Central_South_America\", \"England\": \"Europe\", \"Germany\": \"Europe\",\n",
    "        \"Italy\": \"Europe\", \"Poland\": \"Europe\", \"Portugal\": \"Europe\", \"France\": \"Europe\",\n",
    "        \"Scotland\": \"Europe\", \"Greece\": \"Europe\", \"Ireland\": \"Europe\", \"Hungary\": \"Europe\",\n",
    "        \"Holand-Netherlands\": \"Europe\", \"Yugoslavia\": \"Europe\", \"India\": \"Asia\",\n",
    "        \"Iran\": \"Asia\", \"Philippines\": \"Asia\", \"Cambodia\": \"Asia\", \"Thailand\": \"Asia\",\n",
    "        \"Laos\": \"Asia\", \"Taiwan\": \"Asia\", \"China\": \"Asia\", \"Japan\": \"Asia\", \"Vietnam\": \"Asia\",\n",
    "        \"Hong\": \"Asia\", \"?\": \"Unknown\", \"South\": \"Unknown\"\n",
    "    }\n",
    "    return region_mapping.get(country, \"Other\")\n",
    "\n",
    "adult['native-country'] = adult['native-country'].apply(map_country_to_region)\n",
    "adult = pd.get_dummies(adult, columns=['native-country'], drop_first=True)\n",
    "\n",
    "# Convert binary columns from 0/1 to -1/1 for consistency\n",
    "binary_columns = adult.select_dtypes(include=['int64', 'uint8']).columns\n",
    "for col in binary_columns:\n",
    "    if adult[col].nunique() == 2:  # Check for binary columns\n",
    "        adult[col] = adult[col].apply(lambda x: 1 if x == 1 else -1)\n",
    "\n",
    "for column in adult.columns:\n",
    "    if adult[column].dtype == bool:  # Check if the column is boolean\n",
    "        adult[column] = adult[column].replace({True: 1, False: -1})  # Replace True with 1 and False with -1\n",
    "    elif adult[column].dtype == int and adult[column].nunique() == 2:  # Check if the column has 2 unique values (likely one-hot encoded)\n",
    "        adult[column] = adult[column].replace({1: 1, 0: -1})  # Leave 1 as is, replace 0 with -1\n",
    "\n",
    "adult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                                     0\n",
      "fnlwgt                                  0\n",
      "education-num                           0\n",
      "marital-status                          0\n",
      "capital-gain                            0\n",
      "capital-loss                            0\n",
      "hours-per-week                          0\n",
      "income                                  0\n",
      "workclass_Federal-gov                   0\n",
      "workclass_Local-gov                     0\n",
      "workclass_Never-worked                  0\n",
      "workclass_Private                       0\n",
      "workclass_Self-emp-inc                  0\n",
      "workclass_Self-emp-not-inc              0\n",
      "workclass_State-gov                     0\n",
      "workclass_Without-pay                   0\n",
      "education_11th                          0\n",
      "education_12th                          0\n",
      "education_1st-4th                       0\n",
      "education_5th-6th                       0\n",
      "education_7th-8th                       0\n",
      "education_9th                           0\n",
      "education_Assoc-acdm                    0\n",
      "education_Assoc-voc                     0\n",
      "education_Bachelors                     0\n",
      "education_Doctorate                     0\n",
      "education_HS-grad                       0\n",
      "education_Masters                       0\n",
      "education_Preschool                     0\n",
      "education_Prof-school                   0\n",
      "education_Some-college                  0\n",
      "occupation_Adm-clerical                 0\n",
      "occupation_Armed-Forces                 0\n",
      "occupation_Craft-repair                 0\n",
      "occupation_Exec-managerial              0\n",
      "occupation_Farming-fishing              0\n",
      "occupation_Handlers-cleaners            0\n",
      "occupation_Machine-op-inspct            0\n",
      "occupation_Other-service                0\n",
      "occupation_Priv-house-serv              0\n",
      "occupation_Prof-specialty               0\n",
      "occupation_Protective-serv              0\n",
      "occupation_Sales                        0\n",
      "occupation_Tech-support                 0\n",
      "occupation_Transport-moving             0\n",
      "relationship_Not-in-family              0\n",
      "relationship_Other-relative             0\n",
      "relationship_Own-child                  0\n",
      "relationship_Unmarried                  0\n",
      "relationship_Wife                       0\n",
      "race_Asian-Pac-Islander                 0\n",
      "race_Black                              0\n",
      "race_Other                              0\n",
      "race_White                              0\n",
      "sex_Male                                0\n",
      "native-country_Central_South_America    0\n",
      "native-country_Europe                   0\n",
      "native-country_North_America            0\n",
      "native-country_Other                    0\n",
      "native-country_Unknown                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#ensure no null values\n",
    "print(adult.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the values in the numerical columns have significantly different ranges, it might be beneficial to standardise them, ensuring that the features are on the same scale and contribute equally to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>race_Asian-Pac-Islander</th>\n",
       "      <th>race_Black</th>\n",
       "      <th>race_Other</th>\n",
       "      <th>race_White</th>\n",
       "      <th>sex_Male</th>\n",
       "      <th>native-country_Central_South_America</th>\n",
       "      <th>native-country_Europe</th>\n",
       "      <th>native-country_North_America</th>\n",
       "      <th>native-country_Other</th>\n",
       "      <th>native-country_Unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025996</td>\n",
       "      <td>-1.061979</td>\n",
       "      <td>1.136512</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.146932</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.034087</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.828308</td>\n",
       "      <td>-1.007104</td>\n",
       "      <td>1.136512</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-2.213032</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.046942</td>\n",
       "      <td>0.246034</td>\n",
       "      <td>-0.419335</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.034087</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.047121</td>\n",
       "      <td>0.426663</td>\n",
       "      <td>-1.197259</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.034087</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.776316</td>\n",
       "      <td>1.408530</td>\n",
       "      <td>1.136512</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.034087</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>0.025996</td>\n",
       "      <td>0.243884</td>\n",
       "      <td>1.136512</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.356894</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>1.849433</td>\n",
       "      <td>1.247492</td>\n",
       "      <td>-0.419335</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.034087</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>-0.046942</td>\n",
       "      <td>1.754865</td>\n",
       "      <td>1.136512</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>0.772930</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>0.390683</td>\n",
       "      <td>-1.001612</td>\n",
       "      <td>1.136512</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.587220</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.034087</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>-0.265754</td>\n",
       "      <td>-0.071174</td>\n",
       "      <td>1.136512</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>1.579946</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age    fnlwgt  education-num  marital-status  capital-gain  \\\n",
       "0      0.025996 -1.061979       1.136512              -1      0.146932   \n",
       "1      0.828308 -1.007104       1.136512               1     -0.144804   \n",
       "2     -0.046942  0.246034      -0.419335              -1     -0.144804   \n",
       "3      1.047121  0.426663      -1.197259               1     -0.144804   \n",
       "4     -0.776316  1.408530       1.136512               1     -0.144804   \n",
       "...         ...       ...            ...             ...           ...   \n",
       "48837  0.025996  0.243884       1.136512              -1     -0.144804   \n",
       "48838  1.849433  1.247492      -0.419335              -1     -0.144804   \n",
       "48839 -0.046942  1.754865       1.136512               1     -0.144804   \n",
       "48840  0.390683 -1.001612       1.136512              -1      0.587220   \n",
       "48841 -0.265754 -0.071174       1.136512               1     -0.144804   \n",
       "\n",
       "       capital-loss  hours-per-week  income  workclass_Federal-gov  \\\n",
       "0         -0.217127       -0.034087       1                     -1   \n",
       "1         -0.217127       -2.213032       1                     -1   \n",
       "2         -0.217127       -0.034087       1                     -1   \n",
       "3         -0.217127       -0.034087       1                     -1   \n",
       "4         -0.217127       -0.034087       1                     -1   \n",
       "...             ...             ...     ...                    ...   \n",
       "48837     -0.217127       -0.356894       1                     -1   \n",
       "48838     -0.217127       -0.034087       1                     -1   \n",
       "48839     -0.217127        0.772930       1                     -1   \n",
       "48840     -0.217127       -0.034087       1                     -1   \n",
       "48841     -0.217127        1.579946      -1                     -1   \n",
       "\n",
       "       workclass_Local-gov  ...  race_Asian-Pac-Islander  race_Black  \\\n",
       "0                       -1  ...                       -1          -1   \n",
       "1                       -1  ...                       -1          -1   \n",
       "2                       -1  ...                       -1          -1   \n",
       "3                       -1  ...                       -1           1   \n",
       "4                       -1  ...                       -1           1   \n",
       "...                    ...  ...                      ...         ...   \n",
       "48837                   -1  ...                       -1          -1   \n",
       "48838                   -1  ...                       -1           1   \n",
       "48839                   -1  ...                       -1          -1   \n",
       "48840                   -1  ...                        1          -1   \n",
       "48841                   -1  ...                       -1          -1   \n",
       "\n",
       "       race_Other  race_White  sex_Male  native-country_Central_South_America  \\\n",
       "0              -1           1         1                                    -1   \n",
       "1              -1           1         1                                    -1   \n",
       "2              -1           1         1                                    -1   \n",
       "3              -1          -1         1                                    -1   \n",
       "4              -1          -1        -1                                     1   \n",
       "...           ...         ...       ...                                   ...   \n",
       "48837          -1           1        -1                                    -1   \n",
       "48838          -1          -1         1                                    -1   \n",
       "48839          -1           1         1                                    -1   \n",
       "48840          -1          -1         1                                    -1   \n",
       "48841          -1           1         1                                    -1   \n",
       "\n",
       "       native-country_Europe  native-country_North_America  \\\n",
       "0                         -1                             1   \n",
       "1                         -1                             1   \n",
       "2                         -1                             1   \n",
       "3                         -1                             1   \n",
       "4                         -1                            -1   \n",
       "...                      ...                           ...   \n",
       "48837                     -1                             1   \n",
       "48838                     -1                             1   \n",
       "48839                     -1                             1   \n",
       "48840                     -1                             1   \n",
       "48841                     -1                             1   \n",
       "\n",
       "       native-country_Other  native-country_Unknown  \n",
       "0                        -1                      -1  \n",
       "1                        -1                      -1  \n",
       "2                        -1                      -1  \n",
       "3                        -1                      -1  \n",
       "4                        -1                      -1  \n",
       "...                     ...                     ...  \n",
       "48837                    -1                      -1  \n",
       "48838                    -1                      -1  \n",
       "48839                    -1                      -1  \n",
       "48840                    -1                      -1  \n",
       "48841                    -1                      -1  \n",
       "\n",
       "[48842 rows x 60 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "adult[numerical_cols] = scaler.fit_transform(adult[numerical_cols])\n",
    "\n",
    "adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_adult = adult.drop('income', axis=1)  # Features\n",
    "y_adult = adult['income']  # Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mushroom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['class', 'cap-diameter', 'cap-shape', 'cap-color',\n",
      "       'does-bruise-or-bleed', 'gill-color', 'stem-height', 'stem-width',\n",
      "       'stem-color', 'has-ring', 'habitat', 'season'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7x/jtprqt351tn3_hbj751vpskc0000gn/T/ipykernel_20118/4233719515.py:29: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  mushroom_data_encoded[encoded_columns] = mushroom_data_encoded[encoded_columns].replace({True: 1, False: -1})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>stem-height</th>\n",
       "      <th>stem-width</th>\n",
       "      <th>cap-shape_b</th>\n",
       "      <th>cap-shape_c</th>\n",
       "      <th>cap-shape_f</th>\n",
       "      <th>cap-shape_o</th>\n",
       "      <th>cap-shape_p</th>\n",
       "      <th>cap-shape_s</th>\n",
       "      <th>...</th>\n",
       "      <th>habitat_h</th>\n",
       "      <th>habitat_l</th>\n",
       "      <th>habitat_m</th>\n",
       "      <th>habitat_p</th>\n",
       "      <th>habitat_u</th>\n",
       "      <th>habitat_w</th>\n",
       "      <th>season_a</th>\n",
       "      <th>season_s</th>\n",
       "      <th>season_u</th>\n",
       "      <th>season_w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.619462</td>\n",
       "      <td>3.076705</td>\n",
       "      <td>0.492293</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.873982</td>\n",
       "      <td>3.385311</td>\n",
       "      <td>0.601900</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.393432</td>\n",
       "      <td>3.328931</td>\n",
       "      <td>0.557061</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.412426</td>\n",
       "      <td>2.726555</td>\n",
       "      <td>0.381690</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.501699</td>\n",
       "      <td>2.952075</td>\n",
       "      <td>0.503254</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61064</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.054903</td>\n",
       "      <td>-0.786809</td>\n",
       "      <td>-0.590822</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61065</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.037808</td>\n",
       "      <td>-1.009362</td>\n",
       "      <td>-0.669539</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61066</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.037808</td>\n",
       "      <td>-0.807581</td>\n",
       "      <td>-0.575875</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61067</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.043506</td>\n",
       "      <td>-0.896602</td>\n",
       "      <td>-0.668543</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61068</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.056802</td>\n",
       "      <td>-0.988590</td>\n",
       "      <td>-0.667546</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61069 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class  cap-diameter  stem-height  stem-width  cap-shape_b  cap-shape_c  \\\n",
       "0          1      1.619462     3.076705    0.492293           -1           -1   \n",
       "1          1      1.873982     3.385311    0.601900           -1           -1   \n",
       "2          1      1.393432     3.328931    0.557061           -1           -1   \n",
       "3          1      1.412426     2.726555    0.381690           -1           -1   \n",
       "4          1      1.501699     2.952075    0.503254           -1           -1   \n",
       "...      ...           ...          ...         ...          ...          ...   \n",
       "61064      1     -1.054903    -0.786809   -0.590822           -1           -1   \n",
       "61065      1     -1.037808    -1.009362   -0.669539           -1           -1   \n",
       "61066      1     -1.037808    -0.807581   -0.575875           -1           -1   \n",
       "61067      1     -1.043506    -0.896602   -0.668543           -1           -1   \n",
       "61068      1     -1.056802    -0.988590   -0.667546           -1           -1   \n",
       "\n",
       "       cap-shape_f  cap-shape_o  cap-shape_p  cap-shape_s  ...  habitat_h  \\\n",
       "0               -1           -1           -1           -1  ...         -1   \n",
       "1               -1           -1           -1           -1  ...         -1   \n",
       "2               -1           -1           -1           -1  ...         -1   \n",
       "3                1           -1           -1           -1  ...         -1   \n",
       "4               -1           -1           -1           -1  ...         -1   \n",
       "...            ...          ...          ...          ...  ...        ...   \n",
       "61064           -1           -1           -1            1  ...         -1   \n",
       "61065            1           -1           -1           -1  ...         -1   \n",
       "61066           -1           -1           -1            1  ...         -1   \n",
       "61067            1           -1           -1           -1  ...         -1   \n",
       "61068           -1           -1           -1            1  ...         -1   \n",
       "\n",
       "       habitat_l  habitat_m  habitat_p  habitat_u  habitat_w  season_a  \\\n",
       "0             -1         -1         -1         -1         -1        -1   \n",
       "1             -1         -1         -1         -1         -1        -1   \n",
       "2             -1         -1         -1         -1         -1        -1   \n",
       "3             -1         -1         -1         -1         -1        -1   \n",
       "4             -1         -1         -1         -1         -1        -1   \n",
       "...          ...        ...        ...        ...        ...       ...   \n",
       "61064         -1         -1         -1         -1         -1         1   \n",
       "61065         -1         -1         -1         -1         -1         1   \n",
       "61066         -1         -1         -1         -1         -1        -1   \n",
       "61067         -1         -1         -1         -1         -1        -1   \n",
       "61068         -1         -1         -1         -1         -1        -1   \n",
       "\n",
       "       season_s  season_u  season_w  \n",
       "0            -1        -1         1  \n",
       "1            -1         1        -1  \n",
       "2            -1        -1         1  \n",
       "3            -1        -1         1  \n",
       "4            -1        -1         1  \n",
       "...         ...       ...       ...  \n",
       "61064        -1        -1        -1  \n",
       "61065        -1        -1        -1  \n",
       "61066        -1         1        -1  \n",
       "61067        -1         1        -1  \n",
       "61068        -1         1        -1  \n",
       "\n",
       "[61069 rows x 64 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#primary_data = pd.read_csv('primary_data.csv', delimiter=';')\n",
    "\n",
    "#for the purpose of this classification task, using the seconday data is sufficient \n",
    "# because we do not need descriptors such as name and family, secondary dataset has all the informaiton we need\n",
    "mushroom_data = pd.read_csv('secondary_data.csv', delimiter=';')\n",
    "\n",
    "#drop the columns with missing values\n",
    "mushroom_data = mushroom_data.dropna(axis=1)\n",
    "\n",
    "mushroom_data\n",
    "\n",
    "# Map 'p' (poisonous) to 1 and 'e' (edible) to -1\n",
    "mushroom_data['class'] = mushroom_data['class'].map({'p': 1, 'e': -1})\n",
    "\n",
    "# Print the columns to see if any of them are missing or misspelled\n",
    "print(mushroom_data.columns)\n",
    "\n",
    "columns_to_encode = ['cap-diameter', 'cap-shape', 'cap-color',\n",
    "       'does-bruise-or-bleed', 'gill-color', 'stem-height', 'stem-width',\n",
    "       'stem-color', 'has-ring', 'habitat', 'season']\n",
    "\n",
    "# Step 2: Apply one-hot encoding to the selected columns\n",
    "mushroom_data_encoded = pd.get_dummies(mushroom_data[columns_to_encode], drop_first=False)\n",
    "\n",
    "# Step 3: Reattach the numerical columns and 'class' column\n",
    "mushroom_data_encoded = pd.concat([mushroom_data.drop(columns=columns_to_encode), mushroom_data_encoded], axis=1)\n",
    "\n",
    "encoded_columns = mushroom_data_encoded.columns.difference(['class'])  # Exclude 'class' column\n",
    "mushroom_data_encoded[encoded_columns] = mushroom_data_encoded[encoded_columns].replace({True: 1, False: -1})\n",
    "\n",
    "mushroom_data = mushroom_data_encoded\n",
    "\n",
    "mushroom_data\n",
    "\n",
    "numerical_columns = ['cap-diameter', 'stem-height', 'stem-width']  # Replace with the names of your numerical columns\n",
    "\n",
    "# Step 2: Standardize the numerical columns\n",
    "scaler = StandardScaler()\n",
    "mushroom_data[numerical_columns] = scaler.fit_transform(mushroom_data[numerical_columns])\n",
    "\n",
    "mushroom_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mushroom = mushroom_data.drop(columns=['class']) \n",
    "y_mushroom = mushroom_data['class']  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bank Term Deposit Subscription Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y            0\n",
      "marital      0\n",
      "loan         0\n",
      "age          0\n",
      "pdays        0\n",
      "default      0\n",
      "month        0\n",
      "job          0\n",
      "duration     0\n",
      "campaign     0\n",
      "previous     0\n",
      "housing      0\n",
      "education    0\n",
      "poutcome     0\n",
      "contact      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7x/jtprqt351tn3_hbj751vpskc0000gn/T/ipykernel_20118/2620920488.py:25: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  bank_combined = bank_combined.replace({True: 1, False: -1})\n",
      "/var/folders/7x/jtprqt351tn3_hbj751vpskc0000gn/T/ipykernel_20118/2620920488.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  bank_combined = bank_combined.replace({'yes': 1, 'no': -1})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan</th>\n",
       "      <th>age</th>\n",
       "      <th>pdays</th>\n",
       "      <th>default</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>previous</th>\n",
       "      <th>housing</th>\n",
       "      <th>marital_divorced</th>\n",
       "      <th>marital_married</th>\n",
       "      <th>...</th>\n",
       "      <th>education_basic.6y</th>\n",
       "      <th>education_basic.9y</th>\n",
       "      <th>education_high.school</th>\n",
       "      <th>education_illiterate</th>\n",
       "      <th>education_primary</th>\n",
       "      <th>education_professional.course</th>\n",
       "      <th>education_secondary</th>\n",
       "      <th>education_tertiary</th>\n",
       "      <th>education_university.degree</th>\n",
       "      <th>education_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.660165</td>\n",
       "      <td>-0.983149</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.010394</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.331445</td>\n",
       "      <td>-0.983149</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.415300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.712550</td>\n",
       "      <td>-0.983149</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.705546</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.616171</td>\n",
       "      <td>-0.983149</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.643627</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.712550</td>\n",
       "      <td>-0.983149</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.233413</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86394</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.083794</td>\n",
       "      <td>1.085582</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.292900</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86395</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.521262</td>\n",
       "      <td>1.085582</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.482527</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86396</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.470348</td>\n",
       "      <td>1.085582</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.268242</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86397</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.331445</td>\n",
       "      <td>1.085582</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.710854</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86398</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.178703</td>\n",
       "      <td>1.085582</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.074745</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85409 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       loan       age     pdays default  duration  campaign  previous housing  \\\n",
       "0      -1.0  1.660165 -0.983149      -1  0.010394         1         0       1   \n",
       "1      -1.0  0.331445 -0.983149      -1 -0.415300         1         0       1   \n",
       "2       1.0 -0.712550 -0.983149      -1 -0.705546         1         0       1   \n",
       "3      -1.0  0.616171 -0.983149      -1 -0.643627         1         0       1   \n",
       "4      -1.0 -0.712550 -0.983149      -1 -0.233413         1         0      -1   \n",
       "...     ...       ...       ...     ...       ...       ...       ...     ...   \n",
       "86394  -1.0  3.083794  1.085582      -1  0.292900         1         0       1   \n",
       "86395  -1.0  0.521262  1.085582      -1  0.482527         1         0      -1   \n",
       "86396  -1.0  1.470348  1.085582      -1 -0.268242         2         0       1   \n",
       "86397  -1.0  0.331445  1.085582      -1  0.710854         1         0      -1   \n",
       "86398  -1.0  3.178703  1.085582      -1 -0.074745         3         1       1   \n",
       "\n",
       "       marital_divorced  marital_married  ...  education_basic.6y  \\\n",
       "0                    -1                1  ...                  -1   \n",
       "1                    -1               -1  ...                  -1   \n",
       "2                    -1                1  ...                  -1   \n",
       "3                    -1                1  ...                  -1   \n",
       "4                    -1               -1  ...                  -1   \n",
       "...                 ...              ...  ...                 ...   \n",
       "86394                -1                1  ...                  -1   \n",
       "86395                -1                1  ...                  -1   \n",
       "86396                -1                1  ...                  -1   \n",
       "86397                -1                1  ...                  -1   \n",
       "86398                -1                1  ...                  -1   \n",
       "\n",
       "       education_basic.9y  education_high.school  education_illiterate  \\\n",
       "0                      -1                     -1                    -1   \n",
       "1                      -1                     -1                    -1   \n",
       "2                      -1                     -1                    -1   \n",
       "3                      -1                     -1                    -1   \n",
       "4                      -1                     -1                    -1   \n",
       "...                   ...                    ...                   ...   \n",
       "86394                  -1                     -1                    -1   \n",
       "86395                  -1                     -1                    -1   \n",
       "86396                  -1                     -1                    -1   \n",
       "86397                  -1                     -1                    -1   \n",
       "86398                  -1                     -1                    -1   \n",
       "\n",
       "       education_primary  education_professional.course  education_secondary  \\\n",
       "0                     -1                             -1                   -1   \n",
       "1                     -1                             -1                    1   \n",
       "2                     -1                             -1                    1   \n",
       "3                     -1                             -1                   -1   \n",
       "4                     -1                             -1                   -1   \n",
       "...                  ...                            ...                  ...   \n",
       "86394                 -1                              1                   -1   \n",
       "86395                 -1                              1                   -1   \n",
       "86396                 -1                             -1                   -1   \n",
       "86397                 -1                              1                   -1   \n",
       "86398                 -1                              1                   -1   \n",
       "\n",
       "       education_tertiary  education_university.degree  education_unknown  \n",
       "0                       1                           -1                 -1  \n",
       "1                      -1                           -1                 -1  \n",
       "2                      -1                           -1                 -1  \n",
       "3                      -1                           -1                  1  \n",
       "4                      -1                           -1                  1  \n",
       "...                   ...                          ...                ...  \n",
       "86394                  -1                           -1                 -1  \n",
       "86395                  -1                           -1                 -1  \n",
       "86396                  -1                            1                 -1  \n",
       "86397                  -1                           -1                 -1  \n",
       "86398                  -1                           -1                 -1  \n",
       "\n",
       "[85409 rows x 55 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_full = pd.read_csv('bank-full.csv', sep=';')\n",
    "bank_additional = pd.read_csv('bank-additional-full.csv', sep=';')\n",
    "\n",
    "bank_additional\n",
    "\n",
    "# align the columns by keeping only the common ones\n",
    "common_columns = list(set(bank_full.columns) & set(bank_additional.columns))\n",
    "\n",
    "#align columns before concatenating\n",
    "bank_full_aligned = bank_full[common_columns]\n",
    "bank_additional_aligned = bank_additional[common_columns]\n",
    "\n",
    "# concatenate\n",
    "bank_combined = pd.concat([bank_full_aligned, bank_additional_aligned], axis=0, ignore_index=True)\n",
    "\n",
    "#ensure no missing data\n",
    "print(bank_combined.isnull().sum())\n",
    "\n",
    "bank_combined['loan'] = bank_combined['loan'].map({'yes': 1, 'no': -1})\n",
    "\n",
    "bank_combined\n",
    "\n",
    "bank_combined = pd.get_dummies(bank_combined, columns=['marital', 'job', 'month', 'contact', 'poutcome', 'education'])\n",
    "\n",
    "bank_combined = bank_combined.replace({True: 1, False: -1})\n",
    "bank_combined = bank_combined.replace({'yes': 1, 'no': -1})\n",
    "\n",
    "# Drop the 'y' column\n",
    "bank_combined = bank_combined.drop(columns=['y'])\n",
    "\n",
    "bank_combined = bank_combined.dropna(subset=['loan'])\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "columns_to_scale = ['age', 'pdays', 'duration']\n",
    "\n",
    "# Apply the scaler to the selected columns\n",
    "bank_combined[columns_to_scale] = scaler.fit_transform(bank_combined[columns_to_scale])\n",
    "\n",
    "bank_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bank = bank_combined.drop(columns=['loan'])  # Features (all columns except 'loan')\n",
    "y_bank = bank_combined['loan']  # Target (the 'loan' column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the classifiers on these datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trial 1\n",
      "  Partition 80.0 / 20.0:\n",
      "    SVM Cross-validation Accuracy (mean): 0.8516\n",
      "    Support Vector Machine:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.59      0.65      2353\n",
      "           1       0.88      0.94      0.90      7416\n",
      "\n",
      "    accuracy                           0.85      9769\n",
      "   macro avg       0.81      0.76      0.78      9769\n",
      "weighted avg       0.84      0.85      0.84      9769\n",
      "\n",
      "    Random Forest Cross-validation Accuracy (mean): 0.8413\n",
      "    Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.40      0.54      2353\n",
      "           1       0.84      0.98      0.90      7416\n",
      "\n",
      "    accuracy                           0.84      9769\n",
      "   macro avg       0.84      0.69      0.72      9769\n",
      "weighted avg       0.84      0.84      0.82      9769\n",
      "\n",
      "    AdaBoost Cross-validation Accuracy (mean): 0.8561\n",
      "    AdaBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.58      0.66      2353\n",
      "           1       0.88      0.94      0.91      7416\n",
      "\n",
      "    accuracy                           0.85      9769\n",
      "   macro avg       0.81      0.76      0.78      9769\n",
      "weighted avg       0.85      0.85      0.85      9769\n",
      "\n",
      "  Partition 50.0 / 50.0:\n",
      "    SVM Cross-validation Accuracy (mean): 0.8504\n",
      "    Support Vector Machine:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.73      0.60      0.66      5810\n",
      "           1       0.88      0.93      0.91     18611\n",
      "\n",
      "    accuracy                           0.85     24421\n",
      "   macro avg       0.81      0.77      0.78     24421\n",
      "weighted avg       0.85      0.85      0.85     24421\n",
      "\n",
      "    Random Forest Cross-validation Accuracy (mean): 0.8378\n",
      "    Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.40      0.55      5810\n",
      "           1       0.84      0.98      0.91     18611\n",
      "\n",
      "    accuracy                           0.84     24421\n",
      "   macro avg       0.86      0.69      0.73     24421\n",
      "weighted avg       0.85      0.84      0.82     24421\n",
      "\n",
      "    AdaBoost Cross-validation Accuracy (mean): 0.8537\n",
      "    AdaBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.58      0.66      5810\n",
      "           1       0.88      0.94      0.91     18611\n",
      "\n",
      "    accuracy                           0.85     24421\n",
      "   macro avg       0.81      0.76      0.78     24421\n",
      "weighted avg       0.85      0.85      0.85     24421\n",
      "\n",
      "  Partition 20.0 / 80.0:\n",
      "    SVM Cross-validation Accuracy (mean): 0.8454\n",
      "    Support Vector Machine:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.58      0.65      9325\n",
      "           1       0.88      0.94      0.91     29749\n",
      "\n",
      "    accuracy                           0.85     39074\n",
      "   macro avg       0.81      0.76      0.78     39074\n",
      "weighted avg       0.85      0.85      0.85     39074\n",
      "\n",
      "    Random Forest Cross-validation Accuracy (mean): 0.8352\n",
      "    Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.38      0.53      9325\n",
      "           1       0.84      0.98      0.90     29749\n",
      "\n",
      "    accuracy                           0.84     39074\n",
      "   macro avg       0.85      0.68      0.72     39074\n",
      "weighted avg       0.84      0.84      0.81     39074\n",
      "\n",
      "    AdaBoost Cross-validation Accuracy (mean): 0.8509\n",
      "    AdaBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      0.57      0.65      9325\n",
      "           1       0.88      0.94      0.91     29749\n",
      "\n",
      "    accuracy                           0.85     39074\n",
      "   macro avg       0.82      0.76      0.78     39074\n",
      "weighted avg       0.85      0.85      0.85     39074\n",
      "\n",
      "\n",
      "Trial 2\n",
      "  Partition 80.0 / 20.0:\n",
      "    SVM Cross-validation Accuracy (mean): 0.8525\n",
      "    Support Vector Machine:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.59      0.66      2357\n",
      "           1       0.88      0.93      0.90      7412\n",
      "\n",
      "    accuracy                           0.85      9769\n",
      "   macro avg       0.81      0.76      0.78      9769\n",
      "weighted avg       0.84      0.85      0.84      9769\n",
      "\n",
      "    Random Forest Cross-validation Accuracy (mean): 0.8386\n",
      "    Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.41      0.55      2357\n",
      "           1       0.84      0.98      0.90      7412\n",
      "\n",
      "    accuracy                           0.84      9769\n",
      "   macro avg       0.84      0.69      0.73      9769\n",
      "weighted avg       0.84      0.84      0.82      9769\n",
      "\n",
      "    AdaBoost Cross-validation Accuracy (mean): 0.8556\n",
      "    AdaBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      0.57      0.65      2357\n",
      "           1       0.87      0.94      0.91      7412\n",
      "\n",
      "    accuracy                           0.85      9769\n",
      "   macro avg       0.82      0.76      0.78      9769\n",
      "weighted avg       0.85      0.85      0.84      9769\n",
      "\n",
      "  Partition 50.0 / 50.0:\n",
      "    SVM Cross-validation Accuracy (mean): 0.8558\n",
      "    Support Vector Machine:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.58      0.65      5922\n",
      "           1       0.87      0.93      0.90     18499\n",
      "\n",
      "    accuracy                           0.85     24421\n",
      "   macro avg       0.81      0.76      0.78     24421\n",
      "weighted avg       0.84      0.85      0.84     24421\n",
      "\n",
      "    Random Forest Cross-validation Accuracy (mean): 0.8430\n",
      "    Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.39      0.53      5922\n",
      "           1       0.83      0.98      0.90     18499\n",
      "\n",
      "    accuracy                           0.84     24421\n",
      "   macro avg       0.85      0.68      0.72     24421\n",
      "weighted avg       0.84      0.84      0.81     24421\n",
      "\n",
      "    AdaBoost Cross-validation Accuracy (mean): 0.8583\n",
      "    AdaBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      0.58      0.66      5922\n",
      "           1       0.87      0.94      0.91     18499\n",
      "\n",
      "    accuracy                           0.85     24421\n",
      "   macro avg       0.82      0.76      0.78     24421\n",
      "weighted avg       0.85      0.85      0.85     24421\n",
      "\n",
      "  Partition 20.0 / 80.0:\n",
      "    SVM Cross-validation Accuracy (mean): 0.8530\n",
      "    Support Vector Machine:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.58      0.65      9406\n",
      "           1       0.88      0.94      0.91     29668\n",
      "\n",
      "    accuracy                           0.85     39074\n",
      "   macro avg       0.81      0.76      0.78     39074\n",
      "weighted avg       0.84      0.85      0.84     39074\n",
      "\n",
      "    Random Forest Cross-validation Accuracy (mean): 0.8432\n",
      "    Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.37      0.51      9406\n",
      "           1       0.83      0.98      0.90     29668\n",
      "\n",
      "    accuracy                           0.83     39074\n",
      "   macro avg       0.85      0.67      0.71     39074\n",
      "weighted avg       0.84      0.83      0.81     39074\n",
      "\n",
      "    AdaBoost Cross-validation Accuracy (mean): 0.8557\n",
      "    AdaBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.78      0.54      0.64      9406\n",
      "           1       0.87      0.95      0.91     29668\n",
      "\n",
      "    accuracy                           0.85     39074\n",
      "   macro avg       0.83      0.75      0.77     39074\n",
      "weighted avg       0.85      0.85      0.84     39074\n",
      "\n",
      "\n",
      "Trial 3\n",
      "  Partition 80.0 / 20.0:\n",
      "    SVM Cross-validation Accuracy (mean): 0.8515\n",
      "    Support Vector Machine:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.58      0.65      2346\n",
      "           1       0.88      0.93      0.90      7423\n",
      "\n",
      "    accuracy                           0.85      9769\n",
      "   macro avg       0.81      0.76      0.78      9769\n",
      "weighted avg       0.84      0.85      0.84      9769\n",
      "\n",
      "    Random Forest Cross-validation Accuracy (mean): 0.8396\n",
      "    Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.83      0.41      0.55      2346\n",
      "           1       0.84      0.97      0.90      7423\n",
      "\n",
      "    accuracy                           0.84      9769\n",
      "   macro avg       0.83      0.69      0.73      9769\n",
      "weighted avg       0.84      0.84      0.82      9769\n",
      "\n",
      "    AdaBoost Cross-validation Accuracy (mean): 0.8546\n",
      "    AdaBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      0.59      0.67      2346\n",
      "           1       0.88      0.94      0.91      7423\n",
      "\n",
      "    accuracy                           0.86      9769\n",
      "   macro avg       0.82      0.77      0.79      9769\n",
      "weighted avg       0.85      0.86      0.85      9769\n",
      "\n",
      "  Partition 50.0 / 50.0:\n",
      "    SVM Cross-validation Accuracy (mean): 0.8530\n",
      "    Support Vector Machine:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.57      0.64      5821\n",
      "           1       0.87      0.94      0.90     18600\n",
      "\n",
      "    accuracy                           0.85     24421\n",
      "   macro avg       0.81      0.75      0.77     24421\n",
      "weighted avg       0.84      0.85      0.84     24421\n",
      "\n",
      "    Random Forest Cross-validation Accuracy (mean): 0.8431\n",
      "    Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.40      0.54      5821\n",
      "           1       0.84      0.98      0.90     18600\n",
      "\n",
      "    accuracy                           0.84     24421\n",
      "   macro avg       0.84      0.69      0.72     24421\n",
      "weighted avg       0.84      0.84      0.82     24421\n",
      "\n",
      "    AdaBoost Cross-validation Accuracy (mean): 0.8577\n",
      "    AdaBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.57      0.65      5821\n",
      "           1       0.88      0.94      0.91     18600\n",
      "\n",
      "    accuracy                           0.85     24421\n",
      "   macro avg       0.81      0.76      0.78     24421\n",
      "weighted avg       0.85      0.85      0.85     24421\n",
      "\n",
      "  Partition 20.0 / 80.0:\n",
      "    SVM Cross-validation Accuracy (mean): 0.8505\n",
      "    Support Vector Machine:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.58      0.65      9267\n",
      "           1       0.88      0.94      0.91     29807\n",
      "\n",
      "    accuracy                           0.85     39074\n",
      "   macro avg       0.81      0.76      0.78     39074\n",
      "weighted avg       0.84      0.85      0.85     39074\n",
      "\n",
      "    Random Forest Cross-validation Accuracy (mean): 0.8432\n",
      "    Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.83      0.44      0.57      9267\n",
      "           1       0.85      0.97      0.91     29807\n",
      "\n",
      "    accuracy                           0.85     39074\n",
      "   macro avg       0.84      0.70      0.74     39074\n",
      "weighted avg       0.84      0.85      0.83     39074\n",
      "\n",
      "    AdaBoost Cross-validation Accuracy (mean): 0.8534\n",
      "    AdaBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.76      0.57      0.65      9267\n",
      "           1       0.88      0.94      0.91     29807\n",
      "\n",
      "    accuracy                           0.85     39074\n",
      "   macro avg       0.82      0.76      0.78     39074\n",
      "weighted avg       0.85      0.85      0.85     39074\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "# Outer loop for trials\n",
    "for trial in range(3):  # Run 3 trials\n",
    "    print(f\"\\nTrial {trial + 1}\")\n",
    "\n",
    "    # Shuffle the dataset for each trial\n",
    "    X, y = shuffle(X_adult, y_adult, random_state=trial)\n",
    "\n",
    "    # Define partition sizes for testing\n",
    "    partitions = [0.2, 0.5, 0.8]\n",
    "\n",
    "    # For each partition, train and test models\n",
    "    for i in range(3):  # For each partition\n",
    "        partition_size = partitions[i]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=partition_size, random_state=42)\n",
    "\n",
    "        # Standardize the data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        print(f\"  Partition {100 - (partition_size * 100)} / {partition_size * 100}:\")\n",
    "\n",
    "        # For each model, perform hyperparameter tuning and report classification results\n",
    "        for model_index in range(3):\n",
    "            if model_index == 0:  # Support Vector Machine\n",
    "                classifier_svm = SVC(kernel='linear')\n",
    "                C_list = [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1]\n",
    "                grid_svm = GridSearchCV(classifier_svm, {'C': C_list}, scoring='accuracy', cv=10)\n",
    "                grid_svm.fit(X_train, y_train)\n",
    "\n",
    "                best_svm = grid_svm.best_estimator_\n",
    "\n",
    "                # Cross-validation score for SVM\n",
    "                cv_scores_svm = cross_val_score(best_svm, X_train, y_train, cv=10, scoring='accuracy')\n",
    "                print(f\"    SVM Cross-validation Accuracy (mean): {cv_scores_svm.mean():.4f}\")\n",
    "\n",
    "                pred_svm = best_svm.predict(X_test)\n",
    "                print(f\"    Support Vector Machine:\\n{classification_report(y_test, pred_svm)}\")\n",
    "\n",
    "            elif model_index == 1:  # Random Forest\n",
    "                classifier_rf = RandomForestClassifier(n_estimators=100, criterion='entropy')\n",
    "                max_depth_list = [1, 2, 3, 4, 5]\n",
    "                grid_rf = GridSearchCV(classifier_rf, {'max_depth': max_depth_list}, scoring='accuracy', cv=10)\n",
    "                grid_rf.fit(X_train, y_train)\n",
    "\n",
    "                best_rf = grid_rf.best_estimator_\n",
    "\n",
    "                # Cross-validation score for Random Forest\n",
    "                cv_scores_rf = cross_val_score(best_rf, X_train, y_train, cv=10, scoring='accuracy')\n",
    "                print(f\"    Random Forest Cross-validation Accuracy (mean): {cv_scores_rf.mean():.4f}\")\n",
    "\n",
    "                pred_rf = best_rf.predict(X_test)\n",
    "                print(f\"    Random Forest:\\n{classification_report(y_test, pred_rf)}\")\n",
    "\n",
    "            elif model_index == 2:  # AdaBoost\n",
    "                classifier_ab = AdaBoostClassifier(n_estimators=100, algorithm='SAMME')\n",
    "                learning_rate_list = [0.01, 0.1, 1, 10]\n",
    "                grid_ab = GridSearchCV(classifier_ab, {'learning_rate': learning_rate_list}, scoring='accuracy', cv=10)\n",
    "                grid_ab.fit(X_train, y_train)\n",
    "\n",
    "                best_ab = grid_ab.best_estimator_\n",
    "\n",
    "                # Cross-validation score for AdaBoost\n",
    "                cv_scores_ab = cross_val_score(best_ab, X_train, y_train, cv=10, scoring='accuracy')\n",
    "                print(f\"    AdaBoost Cross-validation Accuracy (mean): {cv_scores_ab.mean():.4f}\")\n",
    "\n",
    "                pred_ab = best_ab.predict(X_test)\n",
    "                print(f\"    AdaBoost:\\n{classification_report(y_test, pred_ab)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/80 Split: Train = (17081, 54) Test = (68328, 54)\n",
      "50/50 Split: Train = (42704, 54) Test = (42705, 54)\n",
      "80/20 Split: Train = (68327, 54) Test = (17082, 54)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 20/80 Split\n",
    "X_train_20, X_test_80, y_train_20, y_test_80 = train_test_split(X, y, test_size=0.8, random_state=42)\n",
    "\n",
    "# 50/50 Split\n",
    "X_train_50, X_test_50, y_train_50, y_test_50 = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# 80/20 Split\n",
    "X_train_80, X_test_20, y_train_80, y_test_20 = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#to verify\n",
    "print(\"20/80 Split: Train =\", X_train_20.shape, \"Test =\", X_test_80.shape)\n",
    "print(\"50/50 Split: Train =\", X_train_50.shape, \"Test =\", X_test_50.shape)\n",
    "print(\"80/20 Split: Train =\", X_train_80.shape, \"Test =\", X_test_20.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1\n",
      "Partition 80/20:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'unknown'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7x/jtprqt351tn3_hbj751vpskc0000gn/T/ipykernel_20118/1467318370.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Partition 20/80:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Scale the numerical features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Define AdaBoost Classifier with SAMME algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/cogs118a/lib/python3.12/site-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             return_tuple = (\n",
      "\u001b[0;32m/opt/anaconda3/envs/cogs118a/lib/python3.12/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1094\u001b[0m                 \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/cogs118a/lib/python3.12/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    874\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m         \"\"\"\n\u001b[1;32m    876\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/cogs118a/lib/python3.12/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1469\u001b[0m                 skip_parameter_validation=(\n\u001b[1;32m   1470\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1472\u001b[0m             \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/cogs118a/lib/python3.12/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m         \"\"\"\n\u001b[1;32m    913\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    915\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/cogs118a/lib/python3.12/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/cogs118a/lib/python3.12/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1009\u001b[0m                         \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m                 raise ValueError(\n\u001b[1;32m   1015\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m                 \u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/cogs118a/lib/python3.12/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/cogs118a/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m   2149\u001b[0m     def __array__(\n\u001b[1;32m   2150\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m     \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2153\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2154\u001b[0m         if (\n\u001b[1;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'unknown'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Outer loop for trials\n",
    "for trial in range(3):\n",
    "    print(f\"Trial {trial + 1}\")\n",
    "    # Shuffle the dataset for each trial\n",
    "    X, y = shuffle(X, y, random_state=trial)\n",
    "\n",
    "    # Middle loop for partitions\n",
    "    for partition in range(3):\n",
    "        if partition == 0:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            print(\"Partition 80/20:\")\n",
    "        elif partition == 1:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "            print(\"Partition 50/50:\")\n",
    "        elif partition == 2:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=42)\n",
    "            print(\"Partition 20/80:\")\n",
    "\n",
    "        # Scale the numerical features\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "\n",
    "        # Define AdaBoost Classifier with SAMME algorithm\n",
    "        ada_classifier = AdaBoostClassifier(algorithm='SAMME', random_state=42)\n",
    "\n",
    "        # Perform GridSearchCV for hyperparameter tuning\n",
    "        param_grid = {'n_estimators': [10, 50, 100, 200], 'learning_rate': [0.01, 0.1, 0.5, 1]}\n",
    "        grid = GridSearchCV(ada_classifier, param_grid, scoring='accuracy', cv=5)  # 5-fold cross-validation\n",
    "        grid.fit(X_train, y_train)\n",
    "\n",
    "        # Train AdaBoost with the best parameters from GridSearch\n",
    "        best_ada = AdaBoostClassifier(\n",
    "            algorithm='SAMME',\n",
    "            n_estimators=grid.best_params_['n_estimators'],\n",
    "            learning_rate=grid.best_params_['learning_rate'],\n",
    "            random_state=42\n",
    "        )\n",
    "        best_ada.fit(X_train, y_train)\n",
    "\n",
    "        # Cross-validation for evaluation\n",
    "        cv_scores = cross_val_score(best_ada, X_train, y_train, cv=5, scoring='accuracy')\n",
    "        print(f\"Cross-Validation Accuracy Scores: {cv_scores}\")\n",
    "        print(f\"Mean CV Accuracy: {cv_scores.mean():.4f}\")\n",
    "\n",
    "        # Predict on the test set\n",
    "        y_pred = best_ada.predict(X_test)\n",
    "\n",
    "        # Print the classification report\n",
    "        print(\"AdaBoost Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogs118a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
